{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.26460859977949286,
  "eval_steps": 500,
  "global_step": 60,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004410143329658214,
      "grad_norm": 0.23657076060771942,
      "learning_rate": 4e-05,
      "loss": 2.4626,
      "step": 1
    },
    {
      "epoch": 0.008820286659316428,
      "grad_norm": 0.2542092502117157,
      "learning_rate": 8e-05,
      "loss": 2.6449,
      "step": 2
    },
    {
      "epoch": 0.013230429988974642,
      "grad_norm": 0.24505223333835602,
      "learning_rate": 0.00012,
      "loss": 2.4496,
      "step": 3
    },
    {
      "epoch": 0.017640573318632856,
      "grad_norm": 0.2871650755405426,
      "learning_rate": 0.00016,
      "loss": 2.6551,
      "step": 4
    },
    {
      "epoch": 0.022050716648291068,
      "grad_norm": 0.2949400544166565,
      "learning_rate": 0.0002,
      "loss": 2.487,
      "step": 5
    },
    {
      "epoch": 0.026460859977949284,
      "grad_norm": 0.34619370102882385,
      "learning_rate": 0.00019636363636363636,
      "loss": 2.5452,
      "step": 6
    },
    {
      "epoch": 0.030871003307607496,
      "grad_norm": 0.28624817728996277,
      "learning_rate": 0.00019272727272727274,
      "loss": 2.2103,
      "step": 7
    },
    {
      "epoch": 0.03528114663726571,
      "grad_norm": 0.27547386288642883,
      "learning_rate": 0.0001890909090909091,
      "loss": 2.3421,
      "step": 8
    },
    {
      "epoch": 0.03969128996692393,
      "grad_norm": 0.2309197187423706,
      "learning_rate": 0.00018545454545454545,
      "loss": 2.2575,
      "step": 9
    },
    {
      "epoch": 0.044101433296582136,
      "grad_norm": 0.19436001777648926,
      "learning_rate": 0.00018181818181818183,
      "loss": 2.0472,
      "step": 10
    },
    {
      "epoch": 0.04851157662624035,
      "grad_norm": 0.19689993560314178,
      "learning_rate": 0.0001781818181818182,
      "loss": 2.0978,
      "step": 11
    },
    {
      "epoch": 0.05292171995589857,
      "grad_norm": 0.22412897646427155,
      "learning_rate": 0.00017454545454545454,
      "loss": 1.981,
      "step": 12
    },
    {
      "epoch": 0.05733186328555678,
      "grad_norm": 0.2463681697845459,
      "learning_rate": 0.0001709090909090909,
      "loss": 1.9019,
      "step": 13
    },
    {
      "epoch": 0.06174200661521499,
      "grad_norm": 0.2725144624710083,
      "learning_rate": 0.00016727272727272728,
      "loss": 1.8969,
      "step": 14
    },
    {
      "epoch": 0.06615214994487321,
      "grad_norm": 0.28842785954475403,
      "learning_rate": 0.00016363636363636366,
      "loss": 1.9085,
      "step": 15
    },
    {
      "epoch": 0.07056229327453142,
      "grad_norm": 0.276215523481369,
      "learning_rate": 0.00016,
      "loss": 1.8891,
      "step": 16
    },
    {
      "epoch": 0.07497243660418963,
      "grad_norm": 0.2761375904083252,
      "learning_rate": 0.00015636363636363637,
      "loss": 1.8644,
      "step": 17
    },
    {
      "epoch": 0.07938257993384785,
      "grad_norm": 0.25690707564353943,
      "learning_rate": 0.00015272727272727275,
      "loss": 1.7607,
      "step": 18
    },
    {
      "epoch": 0.08379272326350606,
      "grad_norm": 0.24754184484481812,
      "learning_rate": 0.0001490909090909091,
      "loss": 1.7265,
      "step": 19
    },
    {
      "epoch": 0.08820286659316427,
      "grad_norm": 0.24412193894386292,
      "learning_rate": 0.00014545454545454546,
      "loss": 1.8108,
      "step": 20
    },
    {
      "epoch": 0.0926130099228225,
      "grad_norm": 0.2552752196788788,
      "learning_rate": 0.00014181818181818184,
      "loss": 1.6108,
      "step": 21
    },
    {
      "epoch": 0.0970231532524807,
      "grad_norm": 0.2513600289821625,
      "learning_rate": 0.0001381818181818182,
      "loss": 1.586,
      "step": 22
    },
    {
      "epoch": 0.10143329658213891,
      "grad_norm": 0.24517469108104706,
      "learning_rate": 0.00013454545454545455,
      "loss": 1.6415,
      "step": 23
    },
    {
      "epoch": 0.10584343991179714,
      "grad_norm": 0.24572008848190308,
      "learning_rate": 0.00013090909090909093,
      "loss": 1.5263,
      "step": 24
    },
    {
      "epoch": 0.11025358324145534,
      "grad_norm": 0.2522294521331787,
      "learning_rate": 0.00012727272727272728,
      "loss": 1.4061,
      "step": 25
    },
    {
      "epoch": 0.11466372657111357,
      "grad_norm": 0.2492835819721222,
      "learning_rate": 0.00012363636363636364,
      "loss": 1.5092,
      "step": 26
    },
    {
      "epoch": 0.11907386990077178,
      "grad_norm": 0.26393768191337585,
      "learning_rate": 0.00012,
      "loss": 1.3817,
      "step": 27
    },
    {
      "epoch": 0.12348401323042998,
      "grad_norm": 0.2628364861011505,
      "learning_rate": 0.00011636363636363636,
      "loss": 1.3116,
      "step": 28
    },
    {
      "epoch": 0.1278941565600882,
      "grad_norm": 0.26757270097732544,
      "learning_rate": 0.00011272727272727272,
      "loss": 1.4262,
      "step": 29
    },
    {
      "epoch": 0.13230429988974643,
      "grad_norm": 0.24817442893981934,
      "learning_rate": 0.00010909090909090909,
      "loss": 1.3415,
      "step": 30
    },
    {
      "epoch": 0.13671444321940462,
      "grad_norm": 0.24500292539596558,
      "learning_rate": 0.00010545454545454545,
      "loss": 1.4549,
      "step": 31
    },
    {
      "epoch": 0.14112458654906285,
      "grad_norm": 0.21884268522262573,
      "learning_rate": 0.00010181818181818181,
      "loss": 1.3197,
      "step": 32
    },
    {
      "epoch": 0.14553472987872107,
      "grad_norm": 0.21187858283519745,
      "learning_rate": 9.818181818181818e-05,
      "loss": 1.2685,
      "step": 33
    },
    {
      "epoch": 0.14994487320837926,
      "grad_norm": 0.205364391207695,
      "learning_rate": 9.454545454545455e-05,
      "loss": 1.2979,
      "step": 34
    },
    {
      "epoch": 0.1543550165380375,
      "grad_norm": 0.2031438797712326,
      "learning_rate": 9.090909090909092e-05,
      "loss": 1.2616,
      "step": 35
    },
    {
      "epoch": 0.1587651598676957,
      "grad_norm": 0.20525898039340973,
      "learning_rate": 8.727272727272727e-05,
      "loss": 1.3414,
      "step": 36
    },
    {
      "epoch": 0.1631753031973539,
      "grad_norm": 0.21531440317630768,
      "learning_rate": 8.363636363636364e-05,
      "loss": 1.4542,
      "step": 37
    },
    {
      "epoch": 0.16758544652701213,
      "grad_norm": 0.18495085835456848,
      "learning_rate": 8e-05,
      "loss": 1.2098,
      "step": 38
    },
    {
      "epoch": 0.17199558985667035,
      "grad_norm": 0.192854642868042,
      "learning_rate": 7.636363636363637e-05,
      "loss": 1.3457,
      "step": 39
    },
    {
      "epoch": 0.17640573318632854,
      "grad_norm": 0.18303588032722473,
      "learning_rate": 7.272727272727273e-05,
      "loss": 1.2788,
      "step": 40
    },
    {
      "epoch": 0.18081587651598677,
      "grad_norm": 0.18724167346954346,
      "learning_rate": 6.90909090909091e-05,
      "loss": 1.1771,
      "step": 41
    },
    {
      "epoch": 0.185226019845645,
      "grad_norm": 0.1966698169708252,
      "learning_rate": 6.545454545454546e-05,
      "loss": 1.2808,
      "step": 42
    },
    {
      "epoch": 0.18963616317530319,
      "grad_norm": 0.1930353343486786,
      "learning_rate": 6.181818181818182e-05,
      "loss": 1.3426,
      "step": 43
    },
    {
      "epoch": 0.1940463065049614,
      "grad_norm": 0.18883517384529114,
      "learning_rate": 5.818181818181818e-05,
      "loss": 1.2207,
      "step": 44
    },
    {
      "epoch": 0.19845644983461963,
      "grad_norm": 0.20664739608764648,
      "learning_rate": 5.4545454545454546e-05,
      "loss": 1.3911,
      "step": 45
    },
    {
      "epoch": 0.20286659316427783,
      "grad_norm": 0.17975720763206482,
      "learning_rate": 5.090909090909091e-05,
      "loss": 1.2183,
      "step": 46
    },
    {
      "epoch": 0.20727673649393605,
      "grad_norm": 0.19336862862110138,
      "learning_rate": 4.7272727272727275e-05,
      "loss": 1.2196,
      "step": 47
    },
    {
      "epoch": 0.21168687982359427,
      "grad_norm": 0.18743298947811127,
      "learning_rate": 4.3636363636363636e-05,
      "loss": 1.2918,
      "step": 48
    },
    {
      "epoch": 0.2160970231532525,
      "grad_norm": 0.188017800450325,
      "learning_rate": 4e-05,
      "loss": 1.2402,
      "step": 49
    },
    {
      "epoch": 0.2205071664829107,
      "grad_norm": 0.182430699467659,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 1.175,
      "step": 50
    },
    {
      "epoch": 0.2249173098125689,
      "grad_norm": 0.18378441035747528,
      "learning_rate": 3.272727272727273e-05,
      "loss": 1.2489,
      "step": 51
    },
    {
      "epoch": 0.22932745314222713,
      "grad_norm": 0.185097798705101,
      "learning_rate": 2.909090909090909e-05,
      "loss": 1.2391,
      "step": 52
    },
    {
      "epoch": 0.23373759647188533,
      "grad_norm": 0.17945000529289246,
      "learning_rate": 2.5454545454545454e-05,
      "loss": 1.1885,
      "step": 53
    },
    {
      "epoch": 0.23814773980154355,
      "grad_norm": 0.1755843460559845,
      "learning_rate": 2.1818181818181818e-05,
      "loss": 1.2403,
      "step": 54
    },
    {
      "epoch": 0.24255788313120177,
      "grad_norm": 0.17164215445518494,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 1.2364,
      "step": 55
    },
    {
      "epoch": 0.24696802646085997,
      "grad_norm": 0.18998265266418457,
      "learning_rate": 1.4545454545454545e-05,
      "loss": 1.4476,
      "step": 56
    },
    {
      "epoch": 0.2513781697905182,
      "grad_norm": 0.19230403006076813,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 1.2922,
      "step": 57
    },
    {
      "epoch": 0.2557883131201764,
      "grad_norm": 0.18883003294467926,
      "learning_rate": 7.272727272727272e-06,
      "loss": 1.2463,
      "step": 58
    },
    {
      "epoch": 0.26019845644983464,
      "grad_norm": 0.17252328991889954,
      "learning_rate": 3.636363636363636e-06,
      "loss": 1.2469,
      "step": 59
    },
    {
      "epoch": 0.26460859977949286,
      "grad_norm": 0.177435040473938,
      "learning_rate": 0.0,
      "loss": 1.1558,
      "step": 60
    }
  ],
  "logging_steps": 1,
  "max_steps": 60,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.194232159961088e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
