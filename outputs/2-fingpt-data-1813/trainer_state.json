{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.26460859977949286,
  "eval_steps": 500,
  "global_step": 60,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004410143329658214,
      "grad_norm": 0.2217024862766266,
      "learning_rate": 4e-05,
      "loss": 2.4142,
      "step": 1
    },
    {
      "epoch": 0.008820286659316428,
      "grad_norm": 0.23931258916854858,
      "learning_rate": 8e-05,
      "loss": 2.6016,
      "step": 2
    },
    {
      "epoch": 0.013230429988974642,
      "grad_norm": 0.23014318943023682,
      "learning_rate": 0.00012,
      "loss": 2.3872,
      "step": 3
    },
    {
      "epoch": 0.017640573318632856,
      "grad_norm": 0.2734992504119873,
      "learning_rate": 0.00016,
      "loss": 2.6157,
      "step": 4
    },
    {
      "epoch": 0.022050716648291068,
      "grad_norm": 0.28253650665283203,
      "learning_rate": 0.0002,
      "loss": 2.4459,
      "step": 5
    },
    {
      "epoch": 0.026460859977949284,
      "grad_norm": 0.3321687579154968,
      "learning_rate": 0.00019636363636363636,
      "loss": 2.4993,
      "step": 6
    },
    {
      "epoch": 0.030871003307607496,
      "grad_norm": 0.282440185546875,
      "learning_rate": 0.00019272727272727274,
      "loss": 2.1624,
      "step": 7
    },
    {
      "epoch": 0.03528114663726571,
      "grad_norm": 0.268689900636673,
      "learning_rate": 0.0001890909090909091,
      "loss": 2.3119,
      "step": 8
    },
    {
      "epoch": 0.03969128996692393,
      "grad_norm": 0.2219172716140747,
      "learning_rate": 0.00018545454545454545,
      "loss": 2.2241,
      "step": 9
    },
    {
      "epoch": 0.044101433296582136,
      "grad_norm": 0.18718531727790833,
      "learning_rate": 0.00018181818181818183,
      "loss": 2.0261,
      "step": 10
    },
    {
      "epoch": 0.04851157662624035,
      "grad_norm": 0.1891224980354309,
      "learning_rate": 0.0001781818181818182,
      "loss": 2.0674,
      "step": 11
    },
    {
      "epoch": 0.05292171995589857,
      "grad_norm": 0.21660977602005005,
      "learning_rate": 0.00017454545454545454,
      "loss": 1.9596,
      "step": 12
    },
    {
      "epoch": 0.05733186328555678,
      "grad_norm": 0.2420399785041809,
      "learning_rate": 0.0001709090909090909,
      "loss": 1.8821,
      "step": 13
    },
    {
      "epoch": 0.06174200661521499,
      "grad_norm": 0.2650071978569031,
      "learning_rate": 0.00016727272727272728,
      "loss": 1.8736,
      "step": 14
    },
    {
      "epoch": 0.06615214994487321,
      "grad_norm": 0.2789562940597534,
      "learning_rate": 0.00016363636363636366,
      "loss": 1.89,
      "step": 15
    },
    {
      "epoch": 0.07056229327453142,
      "grad_norm": 0.2610374391078949,
      "learning_rate": 0.00016,
      "loss": 1.8754,
      "step": 16
    },
    {
      "epoch": 0.07497243660418963,
      "grad_norm": 0.26143741607666016,
      "learning_rate": 0.00015636363636363637,
      "loss": 1.8555,
      "step": 17
    },
    {
      "epoch": 0.07938257993384785,
      "grad_norm": 0.24053972959518433,
      "learning_rate": 0.00015272727272727275,
      "loss": 1.7524,
      "step": 18
    },
    {
      "epoch": 0.08379272326350606,
      "grad_norm": 0.23488163948059082,
      "learning_rate": 0.0001490909090909091,
      "loss": 1.7024,
      "step": 19
    },
    {
      "epoch": 0.08820286659316427,
      "grad_norm": 0.23406949639320374,
      "learning_rate": 0.00014545454545454546,
      "loss": 1.8099,
      "step": 20
    },
    {
      "epoch": 0.0926130099228225,
      "grad_norm": 0.24560488760471344,
      "learning_rate": 0.00014181818181818184,
      "loss": 1.6135,
      "step": 21
    },
    {
      "epoch": 0.0970231532524807,
      "grad_norm": 0.2359766960144043,
      "learning_rate": 0.0001381818181818182,
      "loss": 1.5843,
      "step": 22
    },
    {
      "epoch": 0.10143329658213891,
      "grad_norm": 0.2524344027042389,
      "learning_rate": 0.00013454545454545455,
      "loss": 1.6522,
      "step": 23
    },
    {
      "epoch": 0.10584343991179714,
      "grad_norm": 0.22353683412075043,
      "learning_rate": 0.00013090909090909093,
      "loss": 1.5482,
      "step": 24
    },
    {
      "epoch": 0.11025358324145534,
      "grad_norm": 0.21864424645900726,
      "learning_rate": 0.00012727272727272728,
      "loss": 1.4191,
      "step": 25
    },
    {
      "epoch": 0.11466372657111357,
      "grad_norm": 0.227077454328537,
      "learning_rate": 0.00012363636363636364,
      "loss": 1.5329,
      "step": 26
    },
    {
      "epoch": 0.11907386990077178,
      "grad_norm": 0.22782091796398163,
      "learning_rate": 0.00012,
      "loss": 1.4014,
      "step": 27
    },
    {
      "epoch": 0.12348401323042998,
      "grad_norm": 0.21959902346134186,
      "learning_rate": 0.00011636363636363636,
      "loss": 1.3355,
      "step": 28
    },
    {
      "epoch": 0.1278941565600882,
      "grad_norm": 0.22681456804275513,
      "learning_rate": 0.00011272727272727272,
      "loss": 1.4559,
      "step": 29
    },
    {
      "epoch": 0.13230429988974643,
      "grad_norm": 0.23216763138771057,
      "learning_rate": 0.00010909090909090909,
      "loss": 1.3722,
      "step": 30
    },
    {
      "epoch": 0.13671444321940462,
      "grad_norm": 0.2423311322927475,
      "learning_rate": 0.00010545454545454545,
      "loss": 1.4786,
      "step": 31
    },
    {
      "epoch": 0.14112458654906285,
      "grad_norm": 0.22986575961112976,
      "learning_rate": 0.00010181818181818181,
      "loss": 1.3616,
      "step": 32
    },
    {
      "epoch": 0.14553472987872107,
      "grad_norm": 0.21699301898479462,
      "learning_rate": 9.818181818181818e-05,
      "loss": 1.297,
      "step": 33
    },
    {
      "epoch": 0.14994487320837926,
      "grad_norm": 0.3661194443702698,
      "learning_rate": 9.454545454545455e-05,
      "loss": 1.3293,
      "step": 34
    },
    {
      "epoch": 0.1543550165380375,
      "grad_norm": 0.20340456068515778,
      "learning_rate": 9.090909090909092e-05,
      "loss": 1.2886,
      "step": 35
    },
    {
      "epoch": 0.1587651598676957,
      "grad_norm": 0.20386268198490143,
      "learning_rate": 8.727272727272727e-05,
      "loss": 1.3709,
      "step": 36
    },
    {
      "epoch": 0.1631753031973539,
      "grad_norm": 0.21508236229419708,
      "learning_rate": 8.363636363636364e-05,
      "loss": 1.4919,
      "step": 37
    },
    {
      "epoch": 0.16758544652701213,
      "grad_norm": 0.1870836317539215,
      "learning_rate": 8e-05,
      "loss": 1.2263,
      "step": 38
    },
    {
      "epoch": 0.17199558985667035,
      "grad_norm": 0.19307975471019745,
      "learning_rate": 7.636363636363637e-05,
      "loss": 1.3822,
      "step": 39
    },
    {
      "epoch": 0.17640573318632854,
      "grad_norm": 0.181741863489151,
      "learning_rate": 7.272727272727273e-05,
      "loss": 1.3028,
      "step": 40
    },
    {
      "epoch": 0.18081587651598677,
      "grad_norm": 0.18387265503406525,
      "learning_rate": 6.90909090909091e-05,
      "loss": 1.2094,
      "step": 41
    },
    {
      "epoch": 0.185226019845645,
      "grad_norm": 0.19279786944389343,
      "learning_rate": 6.545454545454546e-05,
      "loss": 1.3225,
      "step": 42
    },
    {
      "epoch": 0.18963616317530319,
      "grad_norm": 0.1913852095603943,
      "learning_rate": 6.181818181818182e-05,
      "loss": 1.3644,
      "step": 43
    },
    {
      "epoch": 0.1940463065049614,
      "grad_norm": 0.19141751527786255,
      "learning_rate": 5.818181818181818e-05,
      "loss": 1.2524,
      "step": 44
    },
    {
      "epoch": 0.19845644983461963,
      "grad_norm": 0.20130886137485504,
      "learning_rate": 5.4545454545454546e-05,
      "loss": 1.4223,
      "step": 45
    },
    {
      "epoch": 0.20286659316427783,
      "grad_norm": 0.17537197470664978,
      "learning_rate": 5.090909090909091e-05,
      "loss": 1.2514,
      "step": 46
    },
    {
      "epoch": 0.20727673649393605,
      "grad_norm": 0.19178406894207,
      "learning_rate": 4.7272727272727275e-05,
      "loss": 1.2481,
      "step": 47
    },
    {
      "epoch": 0.21168687982359427,
      "grad_norm": 0.1865171194076538,
      "learning_rate": 4.3636363636363636e-05,
      "loss": 1.3228,
      "step": 48
    },
    {
      "epoch": 0.2160970231532525,
      "grad_norm": 0.18691690266132355,
      "learning_rate": 4e-05,
      "loss": 1.2814,
      "step": 49
    },
    {
      "epoch": 0.2205071664829107,
      "grad_norm": 0.183542400598526,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 1.2056,
      "step": 50
    },
    {
      "epoch": 0.2249173098125689,
      "grad_norm": 0.18481945991516113,
      "learning_rate": 3.272727272727273e-05,
      "loss": 1.281,
      "step": 51
    },
    {
      "epoch": 0.22932745314222713,
      "grad_norm": 0.182231605052948,
      "learning_rate": 2.909090909090909e-05,
      "loss": 1.2705,
      "step": 52
    },
    {
      "epoch": 0.23373759647188533,
      "grad_norm": 0.18044324219226837,
      "learning_rate": 2.5454545454545454e-05,
      "loss": 1.2243,
      "step": 53
    },
    {
      "epoch": 0.23814773980154355,
      "grad_norm": 0.17511171102523804,
      "learning_rate": 2.1818181818181818e-05,
      "loss": 1.2694,
      "step": 54
    },
    {
      "epoch": 0.24255788313120177,
      "grad_norm": 0.1717996895313263,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 1.2657,
      "step": 55
    },
    {
      "epoch": 0.24696802646085997,
      "grad_norm": 0.18917717039585114,
      "learning_rate": 1.4545454545454545e-05,
      "loss": 1.4795,
      "step": 56
    },
    {
      "epoch": 0.2513781697905182,
      "grad_norm": 0.19097360968589783,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 1.3194,
      "step": 57
    },
    {
      "epoch": 0.2557883131201764,
      "grad_norm": 0.18973763287067413,
      "learning_rate": 7.272727272727272e-06,
      "loss": 1.281,
      "step": 58
    },
    {
      "epoch": 0.26019845644983464,
      "grad_norm": 0.17499540746212006,
      "learning_rate": 3.636363636363636e-06,
      "loss": 1.2852,
      "step": 59
    },
    {
      "epoch": 0.26460859977949286,
      "grad_norm": 0.17982980608940125,
      "learning_rate": 0.0,
      "loss": 1.1837,
      "step": 60
    }
  ],
  "logging_steps": 1,
  "max_steps": 60,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.19419802721239e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
