{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.15768725361366623,
  "eval_steps": 500,
  "global_step": 60,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.002628120893561104,
      "grad_norm": 0.2346799671649933,
      "learning_rate": 4e-05,
      "loss": 2.4877,
      "step": 1
    },
    {
      "epoch": 0.005256241787122208,
      "grad_norm": 0.2662292420864105,
      "learning_rate": 8e-05,
      "loss": 2.5851,
      "step": 2
    },
    {
      "epoch": 0.00788436268068331,
      "grad_norm": 0.23144599795341492,
      "learning_rate": 0.00012,
      "loss": 2.473,
      "step": 3
    },
    {
      "epoch": 0.010512483574244415,
      "grad_norm": 0.2765967845916748,
      "learning_rate": 0.00016,
      "loss": 2.6281,
      "step": 4
    },
    {
      "epoch": 0.013140604467805518,
      "grad_norm": 0.29636427760124207,
      "learning_rate": 0.0002,
      "loss": 2.4548,
      "step": 5
    },
    {
      "epoch": 0.01576872536136662,
      "grad_norm": 0.339965283870697,
      "learning_rate": 0.00019636363636363636,
      "loss": 2.5833,
      "step": 6
    },
    {
      "epoch": 0.018396846254927726,
      "grad_norm": 0.31579118967056274,
      "learning_rate": 0.00019272727272727274,
      "loss": 2.4736,
      "step": 7
    },
    {
      "epoch": 0.02102496714848883,
      "grad_norm": 0.24305643141269684,
      "learning_rate": 0.0001890909090909091,
      "loss": 2.2406,
      "step": 8
    },
    {
      "epoch": 0.023653088042049936,
      "grad_norm": 0.21003010869026184,
      "learning_rate": 0.00018545454545454545,
      "loss": 2.1618,
      "step": 9
    },
    {
      "epoch": 0.026281208935611037,
      "grad_norm": 0.19331960380077362,
      "learning_rate": 0.00018181818181818183,
      "loss": 2.1079,
      "step": 10
    },
    {
      "epoch": 0.02890932982917214,
      "grad_norm": 0.18477533757686615,
      "learning_rate": 0.0001781818181818182,
      "loss": 2.1028,
      "step": 11
    },
    {
      "epoch": 0.03153745072273324,
      "grad_norm": 0.20862746238708496,
      "learning_rate": 0.00017454545454545454,
      "loss": 2.0227,
      "step": 12
    },
    {
      "epoch": 0.03416557161629435,
      "grad_norm": 0.2146192193031311,
      "learning_rate": 0.0001709090909090909,
      "loss": 2.0261,
      "step": 13
    },
    {
      "epoch": 0.03679369250985545,
      "grad_norm": 0.23995019495487213,
      "learning_rate": 0.00016727272727272728,
      "loss": 1.9051,
      "step": 14
    },
    {
      "epoch": 0.03942181340341656,
      "grad_norm": 0.26745840907096863,
      "learning_rate": 0.00016363636363636366,
      "loss": 1.9564,
      "step": 15
    },
    {
      "epoch": 0.04204993429697766,
      "grad_norm": 0.3116385042667389,
      "learning_rate": 0.00016,
      "loss": 1.8318,
      "step": 16
    },
    {
      "epoch": 0.04467805519053877,
      "grad_norm": 0.2761213779449463,
      "learning_rate": 0.00015636363636363637,
      "loss": 1.9642,
      "step": 17
    },
    {
      "epoch": 0.04730617608409987,
      "grad_norm": 0.2835696339607239,
      "learning_rate": 0.00015272727272727275,
      "loss": 1.8194,
      "step": 18
    },
    {
      "epoch": 0.04993429697766097,
      "grad_norm": 0.21822421252727509,
      "learning_rate": 0.0001490909090909091,
      "loss": 1.6988,
      "step": 19
    },
    {
      "epoch": 0.052562417871222074,
      "grad_norm": 0.19835983216762543,
      "learning_rate": 0.00014545454545454546,
      "loss": 1.8981,
      "step": 20
    },
    {
      "epoch": 0.05519053876478318,
      "grad_norm": 0.23472200334072113,
      "learning_rate": 0.00014181818181818184,
      "loss": 1.6594,
      "step": 21
    },
    {
      "epoch": 0.05781865965834428,
      "grad_norm": 0.21569499373435974,
      "learning_rate": 0.0001381818181818182,
      "loss": 1.8283,
      "step": 22
    },
    {
      "epoch": 0.06044678055190539,
      "grad_norm": 0.2112392783164978,
      "learning_rate": 0.00013454545454545455,
      "loss": 1.7698,
      "step": 23
    },
    {
      "epoch": 0.06307490144546649,
      "grad_norm": 0.21915096044540405,
      "learning_rate": 0.00013090909090909093,
      "loss": 1.7722,
      "step": 24
    },
    {
      "epoch": 0.0657030223390276,
      "grad_norm": 0.2250039279460907,
      "learning_rate": 0.00012727272727272728,
      "loss": 1.659,
      "step": 25
    },
    {
      "epoch": 0.0683311432325887,
      "grad_norm": 0.21798786520957947,
      "learning_rate": 0.00012363636363636364,
      "loss": 1.5898,
      "step": 26
    },
    {
      "epoch": 0.07095926412614981,
      "grad_norm": 0.22283367812633514,
      "learning_rate": 0.00012,
      "loss": 1.5935,
      "step": 27
    },
    {
      "epoch": 0.0735873850197109,
      "grad_norm": 0.22034572064876556,
      "learning_rate": 0.00011636363636363636,
      "loss": 1.5986,
      "step": 28
    },
    {
      "epoch": 0.07621550591327202,
      "grad_norm": 0.22219741344451904,
      "learning_rate": 0.00011272727272727272,
      "loss": 1.4801,
      "step": 29
    },
    {
      "epoch": 0.07884362680683311,
      "grad_norm": 0.25439655780792236,
      "learning_rate": 0.00010909090909090909,
      "loss": 1.5067,
      "step": 30
    },
    {
      "epoch": 0.08147174770039421,
      "grad_norm": 0.2320215106010437,
      "learning_rate": 0.00010545454545454545,
      "loss": 1.419,
      "step": 31
    },
    {
      "epoch": 0.08409986859395532,
      "grad_norm": 0.23588953912258148,
      "learning_rate": 0.00010181818181818181,
      "loss": 1.4932,
      "step": 32
    },
    {
      "epoch": 0.08672798948751642,
      "grad_norm": 0.23430553078651428,
      "learning_rate": 9.818181818181818e-05,
      "loss": 1.5487,
      "step": 33
    },
    {
      "epoch": 0.08935611038107753,
      "grad_norm": 0.22675316035747528,
      "learning_rate": 9.454545454545455e-05,
      "loss": 1.4933,
      "step": 34
    },
    {
      "epoch": 0.09198423127463863,
      "grad_norm": 0.21744759380817413,
      "learning_rate": 9.090909090909092e-05,
      "loss": 1.5727,
      "step": 35
    },
    {
      "epoch": 0.09461235216819974,
      "grad_norm": 0.213851660490036,
      "learning_rate": 8.727272727272727e-05,
      "loss": 1.4017,
      "step": 36
    },
    {
      "epoch": 0.09724047306176084,
      "grad_norm": 0.21127018332481384,
      "learning_rate": 8.363636363636364e-05,
      "loss": 1.4981,
      "step": 37
    },
    {
      "epoch": 0.09986859395532194,
      "grad_norm": 0.20471902191638947,
      "learning_rate": 8e-05,
      "loss": 1.4781,
      "step": 38
    },
    {
      "epoch": 0.10249671484888305,
      "grad_norm": 0.20916859805583954,
      "learning_rate": 7.636363636363637e-05,
      "loss": 1.4623,
      "step": 39
    },
    {
      "epoch": 0.10512483574244415,
      "grad_norm": 0.20092403888702393,
      "learning_rate": 7.272727272727273e-05,
      "loss": 1.3392,
      "step": 40
    },
    {
      "epoch": 0.10775295663600526,
      "grad_norm": 0.2037341594696045,
      "learning_rate": 6.90909090909091e-05,
      "loss": 1.5084,
      "step": 41
    },
    {
      "epoch": 0.11038107752956636,
      "grad_norm": 0.20027856528759003,
      "learning_rate": 6.545454545454546e-05,
      "loss": 1.2271,
      "step": 42
    },
    {
      "epoch": 0.11300919842312747,
      "grad_norm": 0.19595122337341309,
      "learning_rate": 6.181818181818182e-05,
      "loss": 1.4185,
      "step": 43
    },
    {
      "epoch": 0.11563731931668857,
      "grad_norm": 0.1992758959531784,
      "learning_rate": 5.818181818181818e-05,
      "loss": 1.4597,
      "step": 44
    },
    {
      "epoch": 0.11826544021024968,
      "grad_norm": 0.19556592404842377,
      "learning_rate": 5.4545454545454546e-05,
      "loss": 1.3801,
      "step": 45
    },
    {
      "epoch": 0.12089356110381078,
      "grad_norm": 0.19636209309101105,
      "learning_rate": 5.090909090909091e-05,
      "loss": 1.3818,
      "step": 46
    },
    {
      "epoch": 0.12352168199737187,
      "grad_norm": 0.18747644126415253,
      "learning_rate": 4.7272727272727275e-05,
      "loss": 1.3003,
      "step": 47
    },
    {
      "epoch": 0.12614980289093297,
      "grad_norm": 0.1923764944076538,
      "learning_rate": 4.3636363636363636e-05,
      "loss": 1.4054,
      "step": 48
    },
    {
      "epoch": 0.1287779237844941,
      "grad_norm": 0.18339566886425018,
      "learning_rate": 4e-05,
      "loss": 1.3649,
      "step": 49
    },
    {
      "epoch": 0.1314060446780552,
      "grad_norm": 0.18575896322727203,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 1.3366,
      "step": 50
    },
    {
      "epoch": 0.1340341655716163,
      "grad_norm": 0.18492886424064636,
      "learning_rate": 3.272727272727273e-05,
      "loss": 1.3495,
      "step": 51
    },
    {
      "epoch": 0.1366622864651774,
      "grad_norm": 0.18588566780090332,
      "learning_rate": 2.909090909090909e-05,
      "loss": 1.4126,
      "step": 52
    },
    {
      "epoch": 0.1392904073587385,
      "grad_norm": 0.18227864801883698,
      "learning_rate": 2.5454545454545454e-05,
      "loss": 1.3534,
      "step": 53
    },
    {
      "epoch": 0.14191852825229961,
      "grad_norm": 0.1942494660615921,
      "learning_rate": 2.1818181818181818e-05,
      "loss": 1.4616,
      "step": 54
    },
    {
      "epoch": 0.1445466491458607,
      "grad_norm": 0.16724663972854614,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 1.316,
      "step": 55
    },
    {
      "epoch": 0.1471747700394218,
      "grad_norm": 0.1616150289773941,
      "learning_rate": 1.4545454545454545e-05,
      "loss": 1.323,
      "step": 56
    },
    {
      "epoch": 0.1498028909329829,
      "grad_norm": 0.17673340439796448,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 1.2535,
      "step": 57
    },
    {
      "epoch": 0.15243101182654403,
      "grad_norm": 0.19068904221057892,
      "learning_rate": 7.272727272727272e-06,
      "loss": 1.3117,
      "step": 58
    },
    {
      "epoch": 0.15505913272010513,
      "grad_norm": 0.18186528980731964,
      "learning_rate": 3.636363636363636e-06,
      "loss": 1.3306,
      "step": 59
    },
    {
      "epoch": 0.15768725361366623,
      "grad_norm": 0.17355357110500336,
      "learning_rate": 0.0,
      "loss": 1.3145,
      "step": 60
    }
  ],
  "logging_steps": 1,
  "max_steps": 60,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.19419802721239e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
