(unsloth_env) hsbcpoc@e87wgt814tvcff7:~/ft/deepseek-r1-distill-training$ python sft.py 
🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.
🦥 Unsloth Zoo will now patch everything to make training faster!
==((====))==  Unsloth 2025.2.4: Fast Qwen2 patching. Transformers: 4.48.3.
   \\   /|    GPU: NVIDIA L20. Max memory: 44.403 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.5.1. CUDA: 8.9. CUDA Toolkit: 12.1. Triton: 3.1.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]
 "-____-"     Free Apache license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.56it/s]
data-00000-of-00001.arrow: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 34.4M/34.4M [00:08<00:00, 4.21MB/s]
Generating train split: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3043/3043 [00:00<00:00, 158618.87 examples/s]
Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3043/3043 [00:00<00:00, 16006.67 examples/s]
Unsloth 2025.2.4 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.
Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3043/3043 [00:02<00:00, 1020.25 examples/s]
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1
   \\   /|    Num examples = 3,043 | Num Epochs = 1
O^O/ \_/ \    Batch size per device = 2 | Gradient Accumulation steps = 4
\        /    Total batch size = 8 | Total steps = 60
 "-____-"     Number of trainable parameters = 40,370,176
{'loss': 2.418, 'grad_norm': 0.23510587215423584, 'learning_rate': 4e-05, 'epoch': 0.0}                                                                                                 
{'loss': 2.5383, 'grad_norm': 0.26529473066329956, 'learning_rate': 8e-05, 'epoch': 0.01}                                                                                               
{'loss': 2.4189, 'grad_norm': 0.23222616314888, 'learning_rate': 0.00012, 'epoch': 0.01}                                                                                                
{'loss': 2.5909, 'grad_norm': 0.27765750885009766, 'learning_rate': 0.00016, 'epoch': 0.01}                                                                                             
{'loss': 2.3909, 'grad_norm': 0.29608646035194397, 'learning_rate': 0.0002, 'epoch': 0.01}                                                                                              
{'loss': 2.5181, 'grad_norm': 0.3352624177932739, 'learning_rate': 0.00019636363636363636, 'epoch': 0.02}                                                                               
{'loss': 2.4459, 'grad_norm': 0.3177672326564789, 'learning_rate': 0.00019272727272727274, 'epoch': 0.02}                                                                               
{'loss': 2.1989, 'grad_norm': 0.24071528017520905, 'learning_rate': 0.0001890909090909091, 'epoch': 0.02}                                                                               
{'loss': 2.115, 'grad_norm': 0.20676562190055847, 'learning_rate': 0.00018545454545454545, 'epoch': 0.02}                                                                               
{'loss': 2.0792, 'grad_norm': 0.1927689015865326, 'learning_rate': 0.00018181818181818183, 'epoch': 0.03}                                                                               
{'loss': 2.0879, 'grad_norm': 0.17792010307312012, 'learning_rate': 0.0001781818181818182, 'epoch': 0.03}                                                                               
{'loss': 1.9999, 'grad_norm': 0.18845652043819427, 'learning_rate': 0.00017454545454545454, 'epoch': 0.03}                                                                              
{'loss': 1.9644, 'grad_norm': 0.19604745507240295, 'learning_rate': 0.0001709090909090909, 'epoch': 0.03}                                                                               
{'loss': 1.8234, 'grad_norm': 0.1961524486541748, 'learning_rate': 0.00016727272727272728, 'epoch': 0.04}                                                                               
{'loss': 1.9332, 'grad_norm': 0.2667727470397949, 'learning_rate': 0.00016363636363636366, 'epoch': 0.04}                                                                               
{'loss': 1.8054, 'grad_norm': 0.3197169601917267, 'learning_rate': 0.00016, 'epoch': 0.04}                                                                                              
{'loss': 1.9431, 'grad_norm': 0.28355562686920166, 'learning_rate': 0.00015636363636363637, 'epoch': 0.04}                                                                              
{'loss': 1.8125, 'grad_norm': 0.2990604043006897, 'learning_rate': 0.00015272727272727275, 'epoch': 0.05}                                                                               
{'loss': 1.6866, 'grad_norm': 0.21760939061641693, 'learning_rate': 0.0001490909090909091, 'epoch': 0.05}                                                                               
{'loss': 1.8782, 'grad_norm': 0.19309057295322418, 'learning_rate': 0.00014545454545454546, 'epoch': 0.05}                                                                              
{'loss': 1.6551, 'grad_norm': 0.23684868216514587, 'learning_rate': 0.00014181818181818184, 'epoch': 0.06}                                                                              
{'loss': 1.8398, 'grad_norm': 0.21505121886730194, 'learning_rate': 0.0001381818181818182, 'epoch': 0.06}                                                                               
{'loss': 1.7357, 'grad_norm': 0.20474423468112946, 'learning_rate': 0.00013454545454545455, 'epoch': 0.06}                                                                              
{'loss': 1.755, 'grad_norm': 0.21307401359081268, 'learning_rate': 0.00013090909090909093, 'epoch': 0.06}                                                                               
{'loss': 1.6578, 'grad_norm': 0.2235405445098877, 'learning_rate': 0.00012727272727272728, 'epoch': 0.07}                                                                               
{'loss': 1.5452, 'grad_norm': 0.2080756425857544, 'learning_rate': 0.00012363636363636364, 'epoch': 0.07}                                                                               
{'loss': 1.5946, 'grad_norm': 0.21934469044208527, 'learning_rate': 0.00012, 'epoch': 0.07}                                                                                             
{'loss': 1.5755, 'grad_norm': 0.21130548417568207, 'learning_rate': 0.00011636363636363636, 'epoch': 0.07}                                                                              
{'loss': 1.4985, 'grad_norm': 0.21610885858535767, 'learning_rate': 0.00011272727272727272, 'epoch': 0.08}                                                                              
{'loss': 1.5161, 'grad_norm': 0.2641277313232422, 'learning_rate': 0.00010909090909090909, 'epoch': 0.08}                                                                               
{'loss': 1.4098, 'grad_norm': 0.2205723375082016, 'learning_rate': 0.00010545454545454545, 'epoch': 0.08}                                                                               
{'loss': 1.4668, 'grad_norm': 0.22763074934482574, 'learning_rate': 0.00010181818181818181, 'epoch': 0.08}                                                                              
{'loss': 1.5224, 'grad_norm': 0.21894098818302155, 'learning_rate': 9.818181818181818e-05, 'epoch': 0.09}                                                                               
{'loss': 1.4956, 'grad_norm': 0.2504335343837738, 'learning_rate': 9.454545454545455e-05, 'epoch': 0.09}                                                                                
{'loss': 1.5856, 'grad_norm': 0.2211112529039383, 'learning_rate': 9.090909090909092e-05, 'epoch': 0.09}                                                                                
{'loss': 1.4258, 'grad_norm': 0.21178855001926422, 'learning_rate': 8.727272727272727e-05, 'epoch': 0.09}                                                                               
{'loss': 1.4994, 'grad_norm': 0.20972126722335815, 'learning_rate': 8.363636363636364e-05, 'epoch': 0.1}                                                                                
{'loss': 1.4816, 'grad_norm': 0.2023555487394333, 'learning_rate': 8e-05, 'epoch': 0.1}                                                                                                 
{'loss': 1.4759, 'grad_norm': 0.1988397240638733, 'learning_rate': 7.636363636363637e-05, 'epoch': 0.1}                                                                                 
{'loss': 1.3126, 'grad_norm': 0.17816273868083954, 'learning_rate': 7.272727272727273e-05, 'epoch': 0.11}                                                                               
{'loss': 1.493, 'grad_norm': 0.20687688887119293, 'learning_rate': 6.90909090909091e-05, 'epoch': 0.11}                                                                                 
{'loss': 1.2014, 'grad_norm': 0.1767151802778244, 'learning_rate': 6.545454545454546e-05, 'epoch': 0.11}                                                                                
{'loss': 1.4241, 'grad_norm': 0.18130895495414734, 'learning_rate': 6.181818181818182e-05, 'epoch': 0.11}                                                                               
{'loss': 1.4532, 'grad_norm': 0.18814149498939514, 'learning_rate': 5.818181818181818e-05, 'epoch': 0.12}                                                                               
{'loss': 1.3833, 'grad_norm': 0.19134242832660675, 'learning_rate': 5.4545454545454546e-05, 'epoch': 0.12}                                                                              
{'loss': 1.364, 'grad_norm': 0.1966477632522583, 'learning_rate': 5.090909090909091e-05, 'epoch': 0.12}                                                                                 
{'loss': 1.3021, 'grad_norm': 0.18343810737133026, 'learning_rate': 4.7272727272727275e-05, 'epoch': 0.12}                                                                              
{'loss': 1.4081, 'grad_norm': 0.18529808521270752, 'learning_rate': 4.3636363636363636e-05, 'epoch': 0.13}                                                                              
{'loss': 1.3468, 'grad_norm': 0.17310209572315216, 'learning_rate': 4e-05, 'epoch': 0.13}                                                                                               
{'loss': 1.3378, 'grad_norm': 0.18572527170181274, 'learning_rate': 3.6363636363636364e-05, 'epoch': 0.13}                                                                              
{'loss': 1.3271, 'grad_norm': 0.1784103661775589, 'learning_rate': 3.272727272727273e-05, 'epoch': 0.13}                                                                                
{'loss': 1.4156, 'grad_norm': 0.18761759996414185, 'learning_rate': 2.909090909090909e-05, 'epoch': 0.14}                                                                               
{'loss': 1.3436, 'grad_norm': 0.17044579982757568, 'learning_rate': 2.5454545454545454e-05, 'epoch': 0.14}                                                                              
{'loss': 1.4731, 'grad_norm': 0.20015817880630493, 'learning_rate': 2.1818181818181818e-05, 'epoch': 0.14}                                                                              
{'loss': 1.3105, 'grad_norm': 0.16978108882904053, 'learning_rate': 1.8181818181818182e-05, 'epoch': 0.14}                                                                              
{'loss': 1.3182, 'grad_norm': 0.15672999620437622, 'learning_rate': 1.4545454545454545e-05, 'epoch': 0.15}                                                                              
{'loss': 1.23, 'grad_norm': 0.16377906501293182, 'learning_rate': 1.0909090909090909e-05, 'epoch': 0.15}                                                                                
{'loss': 1.306, 'grad_norm': 0.18651726841926575, 'learning_rate': 7.272727272727272e-06, 'epoch': 0.15}                                                                                
{'loss': 1.3016, 'grad_norm': 0.180543452501297, 'learning_rate': 3.636363636363636e-06, 'epoch': 0.16}                                                                                 
{'loss': 1.3163, 'grad_norm': 0.1775466799736023, 'learning_rate': 0.0, 'epoch': 0.16}                                                                                                  
{'train_runtime': 512.3857, 'train_samples_per_second': 0.937, 'train_steps_per_second': 0.117, 'train_loss': 1.6792225460211436, 'epoch': 0.16}                                        
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [08:32<00:00,  8.54s/it]
程序运行时间：539.399322271347 秒